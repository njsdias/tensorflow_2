{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Deep Neural Network with TensorFlow 2.0\n",
    "\n",
    "Using the Keras API with TensorFlow, we will be building a neural\n",
    "network with Three hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Here we will use fashion-MNIST data set by Zalando that contains\n",
    "- 70,000 images = 60,000 for training + 10,000 for testing\n",
    "- 10 categories\n",
    "    - t-shirt / top\n",
    "    - trouser\n",
    "    - pullover\n",
    "    - dress\n",
    "    - coat\n",
    "    - sandal\n",
    "    - sneaker\n",
    "    - bag\n",
    "    - ankle boot\n",
    "\n",
    "The images are 28 Ã— 28 pixels of individual articles of clothing,\n",
    "with values ranging from 0 to 255.\n",
    "\n",
    "Dataset: https://bit.ly/2xqIwCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Fashion-MNIST data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels)=ks.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images Dataset Shape: (60000, 28, 28)\n",
      "No. of Training Images Dataset Labels: 60000\n",
      "Test Images Dataset Shape: (10000, 28, 28)\n",
      "No. of Test Images Dataset Labels: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Training Images Dataset Shape: {}'.format(training_images.shape))\n",
    "print('No. of Training Images Dataset Labels: {}'.format(len(training_labels)))\n",
    "print('Test Images Dataset Shape: {}'.format(test_images.shape))\n",
    "print('No. of Test Images Dataset Labels: {}'.format(len(test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize dataset\n",
    "\n",
    "As the pixel values range from 0 to 255, we have to rescale these values\n",
    "in the range 0 to 1 before pushing them to the model. We can scale these\n",
    "values (both for training and test data sets) by dividing the values by 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build layers of Neural Network using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_Layer (Flatten)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_layer_1 (Dense)       (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "Hidden_layer_2 (Dense)       (None, 192)               49344     \n",
      "_________________________________________________________________\n",
      "Hidden_layer_3 (Dense)       (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 276,298\n",
      "Trainable params: 276,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_data_shape = (28,28)\n",
    "hidden_activation_function = 'relu'\n",
    "output_activation_function = 'softmax'\n",
    "\n",
    "# Instantiate Model\n",
    "dnn_model = ks.models.Sequential()\n",
    "\n",
    "# Input Layer\n",
    "dnn_model.add(ks.layers.Flatten(input_shape=input_data_shape, name='Input_Layer'))\n",
    "\n",
    "# Three Hidden Layers\n",
    "dnn_model.add(ks.layers.Dense(256, activation=hidden_activation_function, name='Hidden_layer_1'))\n",
    "dnn_model.add(ks.layers.Dense(192, activation=hidden_activation_function, name='Hidden_layer_2'))\n",
    "dnn_model.add(ks.layers.Dense(128, activation=hidden_activation_function, name='Hidden_layer_3'))\n",
    "\n",
    "# Output Layer\n",
    "dnn_model.add(ks.layers.Dense(10, activation=output_activation_function, name='Output_Layer'))\n",
    "\n",
    "# Build Model\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model\n",
    "\n",
    "To optimze the loss/objective function (cross entropy) we chose Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4831 - accuracy: 0.8245\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3648 - accuracy: 0.8656\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3255 - accuracy: 0.8799\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3037 - accuracy: 0.8875\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2854 - accuracy: 0.8935\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2719 - accuracy: 0.8972\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2583 - accuracy: 0.9024\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2435 - accuracy: 0.9077\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2374 - accuracy: 0.9102\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2277 - accuracy: 0.9129\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2193 - accuracy: 0.9166\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2109 - accuracy: 0.9187\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2068 - accuracy: 0.9203\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1979 - accuracy: 0.9253\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1917 - accuracy: 0.9262\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1876 - accuracy: 0.9278\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1802 - accuracy: 0.9307\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1763 - accuracy: 0.9316\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1717 - accuracy: 0.9328\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1667 - accuracy: 0.9356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2d1a5950b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = 'Adam'\n",
    "loss_function = 'sparse_categorical_crossentropy' \n",
    "metric = ['accuracy']\n",
    "\n",
    "# Model Compile\n",
    "dnn_model.compile(optimizer=optimizer, loss= loss_function, metrics=metric)\n",
    "\n",
    "# Model fit. Number of total fit cicles is set up with epochs parameter\n",
    "dnn_model.fit(training_images, training_labels, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Better results than the architecture that have only one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1523 - accuracy: 0.9412\n",
      "Training Data Accuracy 0.94\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3787 - accuracy: 0.8949\n",
      "Test Data Accuracy 0.89\n"
     ]
    }
   ],
   "source": [
    "# Evaluation with training dataset\n",
    "# it is expected have similary accuracy of last epoch\n",
    "training_loss, training_accuracy =  dnn_model.evaluate(training_images,training_labels)\n",
    "print('Training Data Accuracy {}'.format(round(float(training_accuracy),2)))\n",
    "\n",
    "# Evaluation with test dataset: \n",
    "# It is expected have a litle bit low accuracy \n",
    "# than the evaluation with training dataset\n",
    "test_loss, test_accuracy = dnn_model.evaluate(test_images, test_labels)\n",
    "print('Test Data Accuracy {}'.format(round(float(test_accuracy),2)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
